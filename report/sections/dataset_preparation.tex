\section{Dataset preparation}
\label{sec:dataset}

To analyze the tweets, we needed to collect a dataset of tweets.
We collected tweets related to the keyword \textit{shampoo}. Due to the
limitations of the free Twitter API, we were only able to collect tweets for a
recent period of time. The dataset comprises $42960$ tweets from which 
$59.78\%$ are retweets.

In order to extract some features, we had to do some preprocessing on the
dataset. To compute the term frequency - inverse document frequency, the
occurrence of words in the tweets needed to be computed.

To do so, we had to first create a corpus and then compute the occurrence of
each word. We used Penn Treeban Part-of-Speech Tags in order to remove 
insignificant words so that only nouns, verbs and adjectives were kept from the 
text of the tweets. URLs, stop words or other special characters 
were obviously removed too. Once we had built the corpus, we created a file 
containing each words of the corpus and their occurrence throughout the whole 
dataset's tweet's text.

These words occurrences were later used in order to compute words frequencies 
used in TF and TF-IDF features.

The labels, i.e. a flag telling if a tweet is a retweet, extracted from the 
tweets have an entropy of $0.97$.